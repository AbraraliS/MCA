{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10978eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d265e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11581342",
   "metadata": {},
   "source": [
    "1. Univariate Feature Selection\n",
    "What is it?\n",
    "Univariate Feature Selection means selecting the best features based on individual statistical tests between each feature and the\n",
    "target variable.\n",
    "\"Univariate\" = each feature is evaluated independently.\n",
    "This is useful for removing irrelevant or less important features.\n",
    "What is SelectKBest?\n",
    "SelectKBest is a feature selection method in Scikit-learn that selects the top k features based on a scoring function.\n",
    "Key Components:\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| score_func | The scoring function to evaluate each feature (e.g., f_classif , chi2 ) |\n",
    "| k | Number of top features to keep |\n",
    "\n",
    "Common Scoring Functions:\n",
    "\n",
    "| Function | Use Case | Description |\n",
    "|----------|----------|-------------|\n",
    "| f_classif | Classification | ANOVA F-value between label/feature |\n",
    "| chi2 | Classification (non-negative features) | Chi-squared stats between each feature and target |\n",
    "| mutual_info_classif | Classification | Information gain between each feature and target |\n",
    "| f_regression | Regression | F-value for regression tasks |\n",
    "| mutual_info_regression | Regression | Mutual information for regression tasks |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49977e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate Feature Selection:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.7, 1. ],\n",
       "       [5.1, 1.5],\n",
       "       [5.5, 1.8],\n",
       "       [4.4, 1.4],\n",
       "       [6.1, 2.5],\n",
       "       [4.2, 1.3],\n",
       "       [6.6, 2.1],\n",
       "       [4.5, 1.5],\n",
       "       [1.4, 0.2],\n",
       "       [6.7, 2. ],\n",
       "       [4.1, 1. ],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.3],\n",
       "       [1.9, 0.4],\n",
       "       [3.5, 1. ],\n",
       "       [4.9, 1.8],\n",
       "       [1.9, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.7, 0.5],\n",
       "       [4.2, 1.3],\n",
       "       [1.5, 0.2],\n",
       "       [4.2, 1.2],\n",
       "       [6.7, 2.2],\n",
       "       [1.4, 0.2],\n",
       "       [4.3, 1.3],\n",
       "       [5. , 2. ],\n",
       "       [1.4, 0.2],\n",
       "       [4.8, 1.8],\n",
       "       [5.1, 1.9],\n",
       "       [4. , 1. ],\n",
       "       [4.5, 1.5],\n",
       "       [5.4, 2.3],\n",
       "       [4. , 1.3],\n",
       "       [1.7, 0.4],\n",
       "       [3.3, 1. ],\n",
       "       [5.3, 1.9],\n",
       "       [1.4, 0.2],\n",
       "       [1.2, 0.2],\n",
       "       [3.8, 1.1],\n",
       "       [5. , 1.7],\n",
       "       [1.5, 0.2],\n",
       "       [5.1, 2.4],\n",
       "       [1.5, 0.2],\n",
       "       [1.6, 0.6],\n",
       "       [4.8, 1.8],\n",
       "       [3. , 1.1],\n",
       "       [5.7, 2.3],\n",
       "       [5.1, 1.6],\n",
       "       [5.6, 1.4],\n",
       "       [6.1, 2.3],\n",
       "       [4. , 1.3],\n",
       "       [1.4, 0.2],\n",
       "       [1.1, 0.1],\n",
       "       [5. , 1.5],\n",
       "       [6. , 1.8],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.3],\n",
       "       [1.3, 0.2],\n",
       "       [4.9, 1.5],\n",
       "       [5.6, 2.4],\n",
       "       [1.4, 0.3],\n",
       "       [5.5, 2.1],\n",
       "       [6. , 2.5],\n",
       "       [1.3, 0.2],\n",
       "       [4.7, 1.4],\n",
       "       [4.6, 1.5],\n",
       "       [4.8, 1.8],\n",
       "       [4.7, 1.4],\n",
       "       [5.3, 2.3],\n",
       "       [1.6, 0.2],\n",
       "       [5.4, 2.1],\n",
       "       [4.2, 1.5],\n",
       "       [5.2, 2. ],\n",
       "       [3.5, 1. ],\n",
       "       [3.9, 1.4],\n",
       "       [4.6, 1.4],\n",
       "       [1.3, 0.3],\n",
       "       [4.6, 1.3],\n",
       "       [4.4, 1.2],\n",
       "       [1.5, 0.2],\n",
       "       [4.1, 1.3],\n",
       "       [6.3, 1.8],\n",
       "       [5.7, 2.1],\n",
       "       [1.5, 0.4],\n",
       "       [3.3, 1. ],\n",
       "       [5.7, 2.5],\n",
       "       [5.8, 1.6],\n",
       "       [1.4, 0.1],\n",
       "       [5.6, 2.4],\n",
       "       [1.4, 0.2],\n",
       "       [4.9, 1.5],\n",
       "       [6.1, 1.9],\n",
       "       [5.6, 1.8],\n",
       "       [4.1, 1.3],\n",
       "       [5.5, 1.8],\n",
       "       [4.4, 1.3],\n",
       "       [4.3, 1.3],\n",
       "       [4.9, 2. ],\n",
       "       [5.1, 1.8],\n",
       "       [1.7, 0.2],\n",
       "       [4. , 1.3],\n",
       "       [4.5, 1.7],\n",
       "       [1.2, 0.2],\n",
       "       [4. , 1.2],\n",
       "       [5.9, 2.1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Univariate Feature Selection\n",
    "print(\"Univariate Feature Selection:\")\n",
    "# Apply SelectKBest\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_new = selector.fit_transform(X_train, y_train)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6188fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scores: [ 74.7572012   33.41979913 713.45534904 526.54162416]\n",
      "Selected features: Index(['petal length (cm)', 'petal width (cm)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display scores and selected features\n",
    "print(\"Feature scores:\", selector.scores_)\n",
    "print(\"Selected features:\", X_train.columns[selector.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22378285",
   "metadata": {},
   "source": [
    "2. Recursive Feature Elimination (RFE)\n",
    "To select the best subset of features for your model by recursively removing the least important ones.\n",
    "How it works (Step-by-Step):\n",
    "Train a model (e.g., logistic regression, decision tree) on all features.\n",
    "Rank features based on importance (e.g., model coefficients or feature_importances).\n",
    "Remove the least important feature(s).\n",
    "Repeat the process on the remaining features until:\n",
    " You reach the desired number of features (n_features_to_select)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ca045b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recursive Feature Elimination (RFE):\n",
      "Selected features: Index(['petal length (cm)', 'petal width (cm)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# 2. Recursive Feature Elimination (RFE)\n",
    "print(\"\\nRecursive Feature Elimination (RFE):\")\n",
    "rfe = RFE(estimator=model, n_features_to_select=2)\n",
    "rfe.fit(X_train, y_train)\n",
    "# Display selected features\n",
    "print(\"Selected features:\", X_train.columns[rfe.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d24f864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance from Random Forest:\n",
      "Feature ranking:\n",
      "petal length (cm): 0.4525769063386799\n",
      "petal width (cm): 0.39156253214100667\n",
      "sepal length (cm): 0.12259416960166358\n",
      "sepal width (cm): 0.03326639191864986\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFeature Importance from Random Forest:\")\n",
    "# Display feature importance\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(f\"{X_train.columns[indices[f]]}: {importances[indices[f]]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
